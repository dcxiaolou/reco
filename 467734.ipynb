{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from collections import OrderedDict \n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "\n",
    "from paddle.fluid.dygraph.nn import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['林子大了什么鸟都有太珍稀了\\n', '玻璃瓶里居然装了一幅山水画太美了\\n', '一组用微信表情组成的话有点难度能猜出的人几乎为零\\n', '大大大大大大大大大大大大大实在太大了\\n', '天呐她太漂亮了实在太漂亮了忍不住发给你看看\\n', '最美长寿花看到的人有福了\\n', '肉ྂ体照片罕见实在太罕见了\\n', '世界上最好的长寿药竟然不花一分钱\\n', '一组照片缓解眼睛疲劳赶紧收藏\\n', '令人销魂的照片别不好意思看\\n', '手心里的宝贝太可爱了\\n', '十句话送给晚上睡不着觉的人精辟\\n', '惊滟全果照看了流口水\\n', '牛牛牛让人目瞪口呆的照片\\n', '百万都买不到这张表收藏\\n', '奶奶为孙子编织的毛线大全太可爱了\\n', '会动照片绝了绝了绝了绝了\\n', '太牛了高手在民间开开眼界吧\\n', '月色美人图一辈子看次值了\\n', '再见了朝鲜姑娘\\n', '七彩幸福鸟七彩幸福鸟七彩幸福鸟七彩幸福鸟\\n', '中国女兵太美太震撼了\\n', '神一样的抓拍刚看到第二张我就笑疯了\\n', '个民族个美女很难找齐太美了\\n', '餐厅里的罕见照片太厉害了\\n', '她是最美妲己拍过三级片结婚十年不生孩子丈夫仍然捧在手心岁美如少女\\n', '最美的花最好的祝福送给你\\n', '罕见生子年画最后一张太珍贵了\\n', '全国市市花太美了\\n', '太美了美到心坎上\\n', '罕见罕见太罕见了从没见过这样的鸟\\n', '美美美美美看到的人有福气了\\n', '美丽花鸟美艳极了\\n', '一组看哭了无数中国人的老照片\\n', '罕见珍鸟从未见过太太太太漂亮了\\n', '吉祥长寿相册送给你\\n', '肉上开花难得一见赶紧珍藏\\n', '罕见至极七彩菊花美到窒息\\n', '荷花荷花荷花荷花荷花荷花荷花荷花荷花荷花荷花\\n', '鸟鸟鸟鸟鸟鸟鸟鸟鸟鸟鸟鸟鸟鸟鸟鸟\\n', '刚刚抓拍的真是太太太绝了\\n', '佛佛佛谁看谁有福\\n', '全世界的钱你见过没真是大开眼界\\n', '世界奇观景你绝对不敢相信这是真的\\n', '外国人眼里最美的中国女人居然是年过的她\\n', '我的家庭相册\\n', '绝版相册\\n', '雪中玫瑰美到心醉\\n', '我的相册四\\n', '承德避暑山庄全景美不胜收\\n']\n"
     ]
    }
   ],
   "source": [
    "#读取数据\n",
    "def load_data():\n",
    "    with open(\"./article_data.txt\", \"r\") as f:\n",
    "        corpus = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    return corpus\n",
    "\n",
    "corpus = load_data()\n",
    "\n",
    "print(corpus[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2020-05-15 11:48:33,823-DEBUG: Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "2020-05-15 11:48:34,941-DEBUG: Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.199 seconds.\n",
      "2020-05-15 11:48:35,024-DEBUG: Loading model cost 1.199 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2020-05-15 11:48:35,026-DEBUG: Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['林子', '鸟', '玻璃瓶', '山水画', '表情', '有点', '人', '太漂亮', '太漂亮', '长寿', '人', '肉', '体', '照片', '世界', '长寿', '药', '一分钱', '照片', '眼睛', '令人', '销魂', '照片', '手', '宝贝', '人', '全果', '流口水', '牛牛牛', '人', '照片', '奶奶', '孙子', '编织', '毛线', '照片', '太牛', '高手', '民间', '开眼界', '月色', '美人图', '朝鲜', '姑娘', '七彩', '七彩', '七彩', '七彩', '中国', '女兵']\n"
     ]
    }
   ],
   "source": [
    "# 对语料进行预处理（分词）\n",
    "def data_preprocess(corpus):\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    import jieba.posseg as pseg\n",
    "    import re\n",
    "\n",
    "    filtered_words_list = []\n",
    "\n",
    "    punc = ' ~`!#$%^&*()_+-=|\\;\":/.,?><~·！\\n@#￥%……&*（）——+-=“”：’；、。，？{}'\n",
    "\n",
    "    for sentence in corpus:\n",
    "        sentence = re.sub(r\"[%s]+\" % punc, \"\", sentence)\n",
    "        seg_list = pseg.lcut(sentence)\n",
    "        for seg in seg_list:\n",
    "            if seg.flag.startswith('n'):\n",
    "                filtered_words_list.append(seg.word)\n",
    "    \n",
    "    return filtered_words_list\n",
    "\n",
    "corpus = data_preprocess(corpus)\n",
    "print(corpus[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are totoally 17719 different words in the corpus\n",
      "word 人, its id 0, its word freq 8084\n",
      "word 中国, its id 1, its word freq 3110\n",
      "word 朋友, its id 2, its word freq 2247\n",
      "word 女人, its id 3, its word freq 1504\n",
      "word 广场, its id 4, its word freq 1257\n",
      "word 经典, its id 5, its word freq 1244\n",
      "word 视频, its id 6, its word freq 1137\n",
      "word 男人, its id 7, its word freq 972\n",
      "word 祝福, its id 8, its word freq 966\n",
      "word 人生, its id 9, its word freq 965\n",
      "word 世界, its id 10, its word freq 948\n",
      "word 美女, its id 11, its word freq 908\n",
      "word 战友, its id 12, its word freq 902\n",
      "word 情歌, its id 13, its word freq 865\n",
      "word 歌, its id 14, its word freq 844\n",
      "word 群友, its id 15, its word freq 841\n",
      "word 照片, its id 16, its word freq 828\n",
      "word 农村, its id 17, its word freq 820\n",
      "word 大家, its id 18, its word freq 791\n",
      "word 孩子, its id 19, its word freq 790\n",
      "word 儿子, its id 20, its word freq 765\n",
      "word 小品, its id 21, its word freq 759\n",
      "word 老婆, its id 22, its word freq 719\n",
      "word 钱, its id 23, its word freq 574\n",
      "word 心, its id 24, its word freq 567\n",
      "word 太, its id 25, its word freq 561\n",
      "word 夫妻, its id 26, its word freq 558\n",
      "word 美, its id 27, its word freq 541\n",
      "word 全场, its id 28, its word freq 541\n",
      "word 母亲, its id 29, its word freq 535\n",
      "word 现实, its id 30, its word freq 531\n",
      "word 老兵, its id 31, its word freq 506\n",
      "word 老歌, its id 32, its word freq 500\n",
      "word 曝光, its id 33, its word freq 482\n",
      "word 媳妇, its id 34, its word freq 478\n",
      "word 话, its id 35, its word freq 475\n",
      "word 老人, its id 36, its word freq 473\n",
      "word 老公, its id 37, its word freq 466\n",
      "word 心情, its id 38, its word freq 451\n",
      "word 军人, its id 39, its word freq 435\n",
      "word 事, its id 40, its word freq 433\n",
      "word 小伙, its id 41, its word freq 419\n",
      "word 歌曲, its id 42, its word freq 419\n",
      "word 手机, its id 43, its word freq 416\n",
      "word 国人, its id 44, its word freq 410\n",
      "word 妈妈, its id 45, its word freq 400\n",
      "word 思念, its id 46, its word freq 396\n",
      "word 牛, its id 47, its word freq 390\n",
      "word 父母, its id 48, its word freq 385\n",
      "word 食物, its id 49, its word freq 372\n"
     ]
    }
   ],
   "source": [
    "#构造词典，统计每个词的频率，并根据频率将每个词转换为一个整数id\r\n",
    "def build_dict(corpus):\r\n",
    "    #首先统计每个不同词的频率（出现的次数），使用一个词典记录\r\n",
    "    word_freq_dict = dict()\r\n",
    "    for word in corpus:\r\n",
    "        if word not in word_freq_dict:\r\n",
    "            word_freq_dict[word] = 0\r\n",
    "        word_freq_dict[word] += 1\r\n",
    "\r\n",
    "    #将这个词典中的词，按照出现次数排序，出现次数越高，排序越靠前\r\n",
    "    #一般来说，出现频率高的高频词往往是：I，the，you这种代词，而出现频率低的词，往往是一些名词，如：nlp\r\n",
    "    word_freq_dict = sorted(word_freq_dict.items(), key = lambda x:x[1], reverse = True)\r\n",
    "    \r\n",
    "    #构造3个不同的词典，分别存储，\r\n",
    "    #每个词到id的映射关系：word2id_dict\r\n",
    "    #每个id出现的频率：word2id_freq\r\n",
    "    #每个id到词典映射关系：id2word_dict\r\n",
    "    word2id_dict = dict()\r\n",
    "    word2id_freq = dict()\r\n",
    "    id2word_dict = dict()\r\n",
    "\r\n",
    "    #按照频率，从高到低，开始遍历每个单词，并为这个单词构造一个独一无二的id\r\n",
    "    for word, freq in word_freq_dict:\r\n",
    "        curr_id = len(word2id_dict)\r\n",
    "        word2id_dict[word] = curr_id\r\n",
    "        word2id_freq[word2id_dict[word]] = freq\r\n",
    "        id2word_dict[curr_id] = word\r\n",
    "\r\n",
    "    return word2id_freq, word2id_dict, id2word_dict\r\n",
    "\r\n",
    "word2id_freq, word2id_dict, id2word_dict = build_dict(corpus)\r\n",
    "vocab_size = len(word2id_freq)\r\n",
    "print(\"there are totoally %d different words in the corpus\" % vocab_size)\r\n",
    "for _, (word, word_id) in zip(range(50), word2id_dict.items()):\r\n",
    "    print(\"word %s, its id %d, its word freq %d\" % (word, word_id, word2id_freq[word_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174193 tokens in the corpus\n",
      "[3292, 351, 6707, 1714, 275, 755, 0, 68, 68, 51, 0, 235, 5289, 16, 10, 51, 417, 670, 16, 280, 115, 2449, 16, 191, 821, 0, 9283, 1144, 1715, 0, 16, 199, 236, 4384, 4385, 16, 133, 170, 173, 1013, 5290, 2259, 822, 72, 683, 683, 683, 683, 1, 136]\n"
     ]
    }
   ],
   "source": [
    "#把语料转换为id序列\r\n",
    "def convert_corpus_to_id(corpus, word2id_dict):\r\n",
    "    #使用一个循环，将语料中的每个词替换成对应的id，以便于神经网络进行处理\r\n",
    "    corpus = [word2id_dict[word] for word in corpus]\r\n",
    "    return corpus\r\n",
    "\r\n",
    "corpus = convert_corpus_to_id(corpus, word2id_dict)\r\n",
    "print(\"%d tokens in the corpus\" % len(corpus))\r\n",
    "print(corpus[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93881 tokens in the corpus\n",
      "[3292, 351, 6707, 1714, 68, 235, 5289, 417, 670, 2449, 821, 9283, 1144, 1715, 199, 4384, 4385, 1013, 5290, 2259, 683, 683, 683, 489, 3755, 16, 9284, 2959, 656, 8, 2450, 1540, 4386, 3293, 232, 520, 9285, 128, 128, 119, 51, 683, 981, 551, 551, 551, 551, 551, 551, 551]\n"
     ]
    }
   ],
   "source": [
    "#使用二次采样算法（subsampling）处理语料，强化训练效果\r\n",
    "def subsampling(corpus, word2id_freq):\r\n",
    "    \r\n",
    "    #这个discard函数决定了一个词会不会被替换，这个函数是具有随机性的，每次调用结果不同\r\n",
    "    #如果一个词的频率很大，那么它被遗弃的概率就很大\r\n",
    "    def discard(word_id):\r\n",
    "        return random.uniform(0, 1) < 1 - math.sqrt(\r\n",
    "            1e-4 / word2id_freq[word_id] * len(corpus))\r\n",
    "\r\n",
    "    corpus = [word for word in corpus if not discard(word)]\r\n",
    "    return corpus\r\n",
    "\r\n",
    "corpus = subsampling(corpus, word2id_freq)\r\n",
    "print(\"%d tokens in the corpus\" % len(corpus))\r\n",
    "print(corpus[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center_word 林子, target 鸟, label 1\n",
      "center_word 林子, target 苦心, label 0\n",
      "center_word 林子, target 社员, label 0\n",
      "center_word 林子, target 樱花雨, label 0\n",
      "center_word 林子, target 别提, label 0\n",
      "center_word 林子, target 嫂嫂, label 0\n",
      "center_word 林子, target 开花, label 0\n",
      "center_word 林子, target 耿莲凤, label 0\n",
      "center_word 林子, target 讲座, label 0\n",
      "center_word 林子, target 功名, label 0\n",
      "center_word 林子, target 塘鱼, label 0\n",
      "center_word 鸟, target 林子, label 1\n",
      "center_word 鸟, target 妇科病, label 0\n",
      "center_word 鸟, target 浪费, label 0\n",
      "center_word 鸟, target 公司, label 0\n",
      "center_word 鸟, target 肚儿, label 0\n",
      "center_word 鸟, target 南太平洋, label 0\n",
      "center_word 鸟, target 佛版, label 0\n",
      "center_word 鸟, target 风华, label 0\n",
      "center_word 鸟, target 江, label 0\n",
      "center_word 鸟, target 牛太牛, label 0\n",
      "center_word 鸟, target 技师, label 0\n",
      "center_word 鸟, target 玻璃瓶, label 1\n",
      "center_word 鸟, target 求救信号, label 0\n",
      "center_word 鸟, target 价格便宜, label 0\n",
      "center_word 鸟, target 长寿, label 0\n",
      "center_word 鸟, target 炒青菜, label 0\n",
      "center_word 鸟, target 山竹, label 0\n",
      "center_word 鸟, target 枪式, label 0\n",
      "center_word 鸟, target 文别, label 0\n",
      "center_word 鸟, target 高尔夫球, label 0\n",
      "center_word 鸟, target 红里, label 0\n",
      "center_word 鸟, target 医院院长, label 0\n",
      "center_word 玻璃瓶, target 鸟, label 1\n",
      "center_word 玻璃瓶, target 高端, label 0\n",
      "center_word 玻璃瓶, target 生有幸, label 0\n",
      "center_word 玻璃瓶, target 天指, label 0\n",
      "center_word 玻璃瓶, target 大张伟, label 0\n",
      "center_word 玻璃瓶, target 王二妮, label 0\n",
      "center_word 玻璃瓶, target 性感, label 0\n",
      "center_word 玻璃瓶, target 簸箕, label 0\n",
      "center_word 玻璃瓶, target 芦那韦, label 0\n",
      "center_word 玻璃瓶, target 圈粉, label 0\n",
      "center_word 玻璃瓶, target 耕耘者, label 0\n",
      "center_word 玻璃瓶, target 山水画, label 1\n",
      "center_word 玻璃瓶, target 斗车, label 0\n",
      "center_word 玻璃瓶, target 诱人, label 0\n",
      "center_word 玻璃瓶, target 景美, label 0\n",
      "center_word 玻璃瓶, target 骑牛, label 0\n",
      "center_word 玻璃瓶, target 丹尼, label 0\n"
     ]
    }
   ],
   "source": [
    "#构造数据，准备模型训练\r\n",
    "#max_window_size代表了最大的window_size的大小，程序会根据max_window_size从左到右扫描整个语料\r\n",
    "#negative_sample_num代表了对于每个正样本，需要随机采样多少负样本用于训练，\r\n",
    "#一般来说，negative_sample_num的值越大，训练效果越稳定，但是训练速度越慢。 \r\n",
    "def build_data(corpus, word2id_dict, word2id_freq, max_window_size = 1, negative_sample_num = 10):\r\n",
    "    \r\n",
    "    #使用一个list存储处理好的数据\r\n",
    "    dataset = []\r\n",
    "\r\n",
    "    #从左到右，开始枚举每个中心点的位置\r\n",
    "    for center_word_idx in range(len(corpus)):\r\n",
    "        #以max_window_size为上限，随机采样一个window_size，这样会使得训练更加稳定\r\n",
    "        window_size = random.randint(1, max_window_size)\r\n",
    "        #当前的中心词就是center_word_idx所指向的词\r\n",
    "        center_word = corpus[center_word_idx]\r\n",
    "\r\n",
    "        #以当前中心词为中心，左右两侧在window_size内的词都可以看成是正样本\r\n",
    "        positive_word_range = (max(0, center_word_idx - window_size), min(len(corpus) - 1, center_word_idx + window_size))\r\n",
    "        positive_word_candidates = [corpus[idx] for idx in range(positive_word_range[0], positive_word_range[1]+1) if idx != center_word_idx]\r\n",
    "\r\n",
    "        #对于每个正样本来说，随机采样negative_sample_num个负样本，用于训练\r\n",
    "        for positive_word in positive_word_candidates:\r\n",
    "            #首先把（中心词，正样本，label=1）的三元组数据放入dataset中，\r\n",
    "            #这里label=1表示这个样本是个正样本\r\n",
    "            dataset.append((center_word, positive_word, 1))\r\n",
    "\r\n",
    "            #开始负采样\r\n",
    "            i = 0\r\n",
    "            while i < negative_sample_num:\r\n",
    "                negative_word_candidate = random.randint(0, vocab_size-1)\r\n",
    "\r\n",
    "                if negative_word_candidate not in positive_word_candidates:\r\n",
    "                    #把（中心词，正样本，label=0）的三元组数据放入dataset中，\r\n",
    "                    #这里label=0表示这个样本是个负样本\r\n",
    "                    dataset.append((center_word, negative_word_candidate, 0))\r\n",
    "                    i += 1\r\n",
    "    \r\n",
    "    return dataset\r\n",
    "\r\n",
    "dataset = build_data(corpus, word2id_dict, word2id_freq)\r\n",
    "for _, (center_word, target_word, label) in zip(range(50), dataset):\r\n",
    "    print(\"center_word %s, target %s, label %d\" % (id2word_dict[center_word],\r\n",
    "                                                   id2word_dict[target_word], label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       [  638],\r",
      "       [ 2565],\r",
      "       [ 8531],\r",
      "       [ 6153],\r",
      "       [  356],\r",
      "       [12085],\r",
      "       [ 8063],\r",
      "       [  875],\r",
      "       [ 8904],\r",
      "       [    2],\r",
      "       [ 2043],\r",
      "       [ 2318],\r",
      "       [14629],\r",
      "       [ 3204],\r",
      "       [  615],\r",
      "       [  839],\r",
      "       [ 2104],\r",
      "       [ 1947],\r",
      "       [  748],\r",
      "       [ 1054],\r",
      "       [ 5571],\r",
      "       [ 1173],\r",
      "       [ 4327],\r",
      "       [ 6345],\r",
      "       [ 1038],\r",
      "       [ 2297],\r",
      "       [  738],\r",
      "       [ 4828],\r",
      "       [ 1146],\r",
      "       [ 4195],\r",
      "       [ 2696],\r",
      "       [ 6102],\r",
      "       [ 1500],\r",
      "       [ 1378],\r",
      "       [    0],\r",
      "       [  891],\r",
      "       [ 2240],\r",
      "       [ 6544],\r",
      "       [  240],\r",
      "       [14992],\r",
      "       [ 3147],\r",
      "       [  296],\r",
      "       [ 2773],\r",
      "       [ 1396],\r",
      "       [ 1879],\r",
      "       [   46],\r",
      "       [ 1894],\r",
      "       [  122],\r",
      "       [ 3169],\r",
      "       [  296],\r",
      "       [ 1681],\r",
      "       [  686],\r",
      "       [  210],\r",
      "       [ 1275],\r",
      "       [   71],\r",
      "       [  482],\r",
      "       [ 6029],\r",
      "       [   19],\r",
      "       [  353],\r",
      "       [  503],\r",
      "       [  781],\r",
      "       [  482],\r",
      "       [  850],\r",
      "       [ 3741],\r",
      "       [12959],\r",
      "       [ 1882],\r",
      "       [  867],\r",
      "       [  155],\r",
      "       [ 4461],\r",
      "       [ 2171],\r",
      "       [ 3943],\r",
      "       [  284],\r",
      "       [  642],\r",
      "       [ 1213],\r",
      "       [ 2513],\r",
      "       [ 8050],\r",
      "       [ 1668],\r",
      "       [ 8679],\r",
      "       [  366]]), array([[ 8595],\r",
      "       [11512],\r",
      "       [ 4223],\r",
      "       [ 6499],\r",
      "       [11443],\r",
      "       [ 2590],\r",
      "       [ 8486],\r",
      "       [13719],\r",
      "       [ 8725],\r",
      "       [16205],\r",
      "       [11118],\r",
      "       [  548],\r",
      "       [ 1367],\r",
      "       [ 6393],\r",
      "       [ 7426],\r",
      "       [ 8969],\r",
      "       [ 3710],\r",
      "       [ 5734],\r",
      "       [ 7109],\r",
      "       [15002],\r",
      "       [ 8228],\r",
      "       [  531],\r",
      "       [10311],\r",
      "       [ 9909],\r",
      "       [ 7499],\r",
      "       [  778],\r",
      "       [ 1040],\r",
      "       [ 6932],\r",
      "       [16688],\r",
      "       [ 1900],\r",
      "       [12392],\r",
      "       [ 2494],\r",
      "       [ 4280],\r",
      "       [11124],\r",
      "       [  813],\r",
      "       [ 1671],\r",
      "       [  860],\r",
      "       [  785],\r",
      "       [ 6458],\r",
      "       [14677],\r",
      "       [ 1106],\r",
      "       [16009],\r",
      "       [ 5848],\r",
      "       [   47],\r",
      "       [ 7498],\r",
      "       [10909],\r",
      "       [ 4734],\r",
      "       [ 5040],\r",
      "       [ 7408],\r",
      "       [ 1604],\r",
      "       [14781],\r",
      "       [10212],\r",
      "       [ 5705],\r",
      "       [ 4906],\r",
      "       [ 8135],\r",
      "       [ 7311],\r",
      "       [ 7878],\r",
      "       [ 2772],\r",
      "       [10211],\r",
      "       [ 4828],\r",
      "       [ 1975],\r",
      "       [ 6619],\r",
      "       [ 2837],\r",
      "       [ 6265],\r",
      "       [ 3601],\r",
      "       [10153],\r",
      "       [  354],\r",
      "       [ 1151],\r",
      "       [12635],\r",
      "       [ 3125],\r",
      "       [ 9827],\r",
      "       [ 1127],\r",
      "       [ 7010],\r",
      "       [10878],\r",
      "       [14300],\r",
      "       [14043],\r",
      "       [11871],\r",
      "       [11589],\r",
      "       [10376],\r",
      "       [ 1806],\r",
      "       [  796],\r",
      "       [17290],\r",
      "       [ 2465],\r",
      "       [12739],\r",
      "       [ 6806],\r",
      "       [   79],\r",
      "       [12079],\r",
      "       [10737],\r",
      "       [11624],\r",
      "       [  105],\r",
      "       [ 4199],\r",
      "       [16117],\r",
      "       [ 1822],\r",
      "       [ 2556],\r",
      "       [10086],\r",
      "       [ 6036],\r",
      "       [ 3967],\r",
      "       [   48],\r",
      "       [15349],\r",
      "       [15100],\r",
      "       [ 7179],\r",
      "       [ 8370],\r",
      "       [  771],\r",
      "       [ 5297],\r",
      "       [ 8601],\r",
      "       [17295],\r",
      "       [13293],\r",
      "       [ 8621],\r",
      "       [13169],\r",
      "       [14013],\r",
      "       [13693],\r",
      "       [ 4483],\r",
      "       [17161],\r",
      "       [12966],\r",
      "       [10117],\r",
      "       [17462],\r",
      "       [ 4056],\r",
      "       [11070],\r",
      "       [  206],\r",
      "       [   20],\r",
      "       [13316],\r",
      "       [ 9703],\r",
      "       [14889],\r",
      "       [ 4175],\r",
      "       [ 7115],\r",
      "       [16629],\r",
      "       [10044],\r",
      "       [ 7267]]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\r",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\r",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))\r",
      "(array([[ 9032],\r",
      "       [ 5921],\r",
      "       [  563],\r",
      "       [  681],\r",
      "       [ 6847],\r",
      "       [  427],\r",
      "       [ 2242],\r",
      "       [ 1224],\r",
      "       [   73],\r",
      "       [  548],\r",
      "       [  730],\r",
      "       [ 2319],\r",
      "       [   89],\r",
      "       [   14],\r",
      "       [  348],\r",
      "       [ 6980],\r",
      "       [  817],\r",
      "       [ 1794],\r",
      "       [   32],\r",
      "       [ 1974],\r",
      "       [ 2514],\r",
      "       [ 8248],\r",
      "       [ 5599],\r",
      "       [ 7521],\r",
      "       [ 5427],\r",
      "       [ 1996],\r",
      "       [   73],\r",
      "       [ 3415],\r",
      "       [ 4408],\r",
      "       [   33],\r",
      "       [  845],\r",
      "       [10916],\r",
      "       [ 7268],\r",
      "       [ 6473],\r",
      "       [ 3675],\r",
      "       [ 7346],\r",
      "       [ 1557],\r",
      "       [ 2245],\r",
      "       [ 5151],\r",
      "       [  587],\r",
      "       [  551],\r",
      "       [16516],\r",
      "       [ 1141],\r",
      "       [ 1775],\r",
      "       [  860],\r",
      "       [    1],\r",
      "       [ 1743],\r",
      "       [ 1094],\r",
      "       [  366],\r",
      "       [ 4339],\r",
      "       [ 1939],\r",
      "       [   78],\r",
      "       [   39],\r",
      "       [ 4197],\r",
      "       [ 4605],\r",
      "       [  223],\r",
      "       [   89],\r",
      "       [  642],\r",
      "       [  418],\r",
      "       [  744],\r",
      "       [ 2611],\r",
      "       [  403],\r",
      "       [  399],\r",
      "       [12889],\r",
      "       [ 2997],\r",
      "       [  655],\r",
      "       [ 1545],\r",
      "       [  574],\r",
      "       [ 9260],\r",
      "       [ 3917],\r",
      "       [ 1584],\r",
      "       [ 1218],\r",
      "       [ 2537],\r",
      "       [ 8713],\r",
      "       [ 2050],\r",
      "       [   60],\r",
      "       [   72],\r",
      "       [ 4159],\r",
      "       [ 2069],\r",
      "       [   45],\r",
      "       [ 4985],\r",
      "       [ 1126],\r",
      "       [ 4746],\r",
      "       [ 2560],\r",
      "       [ 2974],\r",
      "       [ 6463],\r",
      "       [ 6172],\r",
      "       [  779],\r",
      "       [ 3695],\r",
      "       [  149],\r",
      "       [  730],\r",
      "       [ 1186],\r",
      "       [   78],\r",
      "       [  154],\r",
      "       [  170],\r",
      "       [  760],\r",
      "       [10130],\r",
      "       [ 3131],\r",
      "       [  446],\r",
      "       [ 2000],\r",
      "       [ 1504],\r",
      "       [ 1607],\r",
      "       [ 2556],\r",
      "       [ 1304],\r",
      "       [  187],\r",
      "       [  333],\r",
      "       [  890],\r",
      "       [  135],\r",
      "       [  145],\r",
      "       [ 8441],\r",
      "       [ 3492],\r",
      "       [  691],\r",
      "       [  338],\r",
      "       [15581],\r",
      "       [ 8464],\r",
      "       [  171],\r",
      "       [ 3763],\r",
      "       [   12],\r",
      "       [ 1502],\r",
      "       [    3],\r",
      "       [ 1758],\r",
      "       [  169],\r",
      "       [ 1072],\r",
      "       [ 1580],\r",
      "       [    6],\r",
      "       [ 1113],\r",
      "       [13714],\r",
      "       [  248]]), array([[16794],\r",
      "       [ 9717],\r",
      "       [ 5654],\r",
      "       [ 1944],\r",
      "       [ 1620],\r",
      "       [ 8407],\r",
      "       [ 2435],\r",
      "       [13686],\r",
      "       [16823],\r",
      "       [ 6331],\r",
      "       [12004],\r",
      "       [ 9104],\r",
      "       [ 8818],\r",
      "       [ 3306],\r",
      "       [ 3123],\r",
      "       [ 5420],\r",
      "       [  677],\r",
      "       [ 2828],\r",
      "       [ 9259],\r",
      "       [ 1712],\r",
      "       [ 1623],\r",
      "       [10107],\r",
      "       [ 8720],\r",
      "       [10713],\r",
      "       [ 5437],\r",
      "       [13872],\r",
      "       [ 9159],\r",
      "       [ 8328],\r",
      "       [ 5963],\r",
      "       [12646],\r",
      "       [16637],\r",
      "       [ 6350],\r",
      "       [  193],\r",
      "       [  766],\r",
      "       [ 4404],\r",
      "       [ 3791],\r",
      "       [11957],\r",
      "       [ 4215],\r",
      "       [  319],\r",
      "       [ 2081],\r",
      "       [ 5944],\r",
      "       [ 8876],\r",
      "       [ 1652],\r",
      "       [13615],\r",
      "       [17506],\r",
      "       [ 7313],\r",
      "       [ 1979],\r",
      "       [17510],\r",
      "       [ 3334],\r",
      "       [15787],\r",
      "       [12577],\r",
      "       [  693],\r",
      "       [ 9108],\r",
      "       [11844],\r",
      "       [  354],\r",
      "       [16734],\r",
      "       [11641],\r",
      "       [  313],\r",
      "       [ 8691],\r",
      "       [  347],\r",
      "       [15219],\r",
      "       [15996],\r",
      "       [   10],\r",
      "       [ 6124],\r",
      "       [ 9585],\r",
      "       [14948],\r",
      "       [ 3919],\r",
      "       [17644],\r",
      "       [10005],\r",
      "       [14554],\r",
      "       [ 7942],\r",
      "       [16414],\r",
      "       [ 5962],\r",
      "       [14746],\r",
      "       [13058],\r",
      "       [ 7736],\r",
      "       [16756],\r",
      "       [ 6601],\r",
      "       [16821],\r",
      "       [ 4997],\r",
      "       [ 8656],\r",
      "       [10796],\r",
      "       [ 3630],\r",
      "       [  132],\r",
      "       [11839],\r",
      "       [10259],\r",
      "       [15590],\r",
      "       [ 1772],\r",
      "       [ 2213],\r",
      "       [ 4577],\r",
      "       [10858],\r",
      "       [ 5730],\r",
      "       [11786],\r",
      "       [ 8342],\r",
      "       [12755],\r",
      "       [ 2629],\r",
      "       [ 9947],\r",
      "       [ 9530],\r",
      "       [13423],\r",
      "       [  587],\r",
      "       [ 3839],\r",
      "       [ 4777],\r",
      "       [16813],\r",
      "       [ 1269],\r",
      "       [11566],\r",
      "       [12824],\r",
      "       [ 1602],\r",
      "       [ 2800],\r",
      "       [ 9463],\r",
      "       [ 5919],\r",
      "       [13074],\r",
      "       [15019],\r",
      "       [ 5054],\r",
      "       [15346],\r",
      "       [16387],\r",
      "       [ 4864],\r",
      "       [ 2462],\r",
      "       [14005],\r",
      "       [16050],\r",
      "       [ 2411],\r",
      "       [ 4682],\r",
      "       [ 4223],\r",
      "       [16012],\r",
      "       [ 4260],\r",
      "       [ 1428],\r",
      "       [ 8338],\r",
      "       [ 1289],\r",
      "       [10296]]), array([0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\r",
      "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))\r",
      "(array([[14605],\r",
      "       [ 1028],\r",
      "       [  749],\r",
      "       [ 1379],\r",
      "       [ 1455],\r",
      "       [  747],\r",
      "       [ 7323],\r",
      "       [ 5083],\r",
      "       [ 3320],\r",
      "       [ 1744],\r",
      "       [12948],\r",
      "       [  652],\r",
      "       [  678],\r",
      "       [ 3570],\r",
      "       [  295],\r",
      "       [  451],\r",
      "       [   99],\r",
      "       [ 3576],\r",
      "       [ 6747],\r",
      "       [ 1042],\r",
      "       [11819],\r",
      "       [ 3812],\r",
      "       [    2],\r",
      "       [16201],\r",
      "       [ 1402],\r",
      "       [  552],\r",
      "       [  198],\r",
      "       [  405],\r",
      "       [  358],\r",
      "       [  786],\r",
      "       [ 4553],\r",
      "       [ 1693],\r",
      "       [  189],\r",
      "       [   20],\r",
      "       [ 3633],\r",
      "       [ 1996],\r",
      "       [15371],\r",
      "       [  712],\r",
      "       [  942],\r",
      "       [ 2386],\r",
      "       [  340],\r",
      "       [  439],\r",
      "       [  924],\r",
      "       [   17],\r",
      "       [ 2262],\r",
      "       [ 1449],\r",
      "       [  164],\r",
      "       [  474],\r",
      "       [ 1183],\r",
      "       [ 2293],\r",
      "       [   51],\r",
      "       [ 8723],\r",
      "       [  188],\r",
      "       [   26],\r",
      "       [ 5802],\r",
      "       [  251],\r",
      "       [ 1662],\r",
      "       [  417],\r",
      "       [  165],\r",
      "       [15298],\r",
      "       [  737],\r",
      "       [ 1934],\r",
      "       [ 1068],\r",
      "       [ 6432],\r",
      "       [  335],\r",
      "       [  863],\r",
      "       [ 1853],\r",
      "       [ 1877],\r",
      "       [10447],\r",
      "       [ 1520],\r",
      "       [  597],\r",
      "       [13103],\r",
      "       [15236],\r",
      "       [13608],\r",
      "       [  209],\r",
      "       [   32],\r",
      "       [14202],\r",
      "       [ 2255],\r",
      "       [  969],\r",
      "       [ 3489],\r",
      "       [ 1746],\r",
      "       [  372],\r",
      "       [  111],\r",
      "       [  993],\r",
      "       [  147],\r",
      "       [ 1359],\r",
      "       [   42],\r",
      "       [ 1427],\r",
      "       [14878],\r",
      "       [  350],\r",
      "       [ 3319],\r",
      "       [  792],\r",
      "       [  607],\r",
      "       [   70],\r",
      "       [  130],\r",
      "       [ 1717],\r",
      "       [ 8519],\r",
      "       [  612],\r",
      "       [ 6002],\r",
      "       [ 3606],\r",
      "       [ 7468],\r",
      "       [  595],\r",
      "       [ 2261],\r",
      "       [ 2155],\r",
      "       [11144],\r",
      "       [  126],\r",
      "       [ 3691],\r",
      "       [  283],\r",
      "       [ 2141],\r",
      "       [  318],\r",
      "       [13869],\r",
      "       [ 1101],\r",
      "       [ 3918],\r",
      "       [  309],\r",
      "       [ 6301],\r",
      "       [ 2864],\r",
      "       [ 6361],\r",
      "       [10689],\r",
      "       [ 2835],\r",
      "       [    0],\r",
      "       [  241],\r",
      "       [ 3147],\r",
      "       [  600],\r",
      "       [ 1595],\r",
      "       [ 4178],\r",
      "       [ 1844],\r",
      "       [ 4620],\r",
      "       [  267]]), array([[11142],\r",
      "       [12044],\r",
      "       [10426],\r",
      "       [ 8179],\r",
      "       [ 2098],\r",
      "       [10318],\r",
      "       [11402],\r",
      "       [12314],\r",
      "       [ 3621],\r",
      "       [ 9983],\r",
      "       [ 7347],\r",
      "       [ 9722],\r",
      "       [17177],\r",
      "       [ 3069],\r",
      "       [11461],\r",
      "       [17623],\r",
      "       [17036],\r",
      "       [10370],\r",
      "       [ 4819],\r",
      "       [11456],\r",
      "       [11424],\r",
      "       [ 1207],\r",
      "       [ 2455],\r",
      "       [ 9066],\r",
      "       [ 8555],\r",
      "       [16279],\r",
      "       [ 7622],\r",
      "       [17093],\r",
      "       [ 7325],\r",
      "       [ 3980],\r",
      "       [14522],\r",
      "       [11056],\r",
      "       [12433],\r",
      "       [12852],\r",
      "       [15750],\r",
      "       [ 8831],\r",
      "       [ 4588],\r",
      "       [10205],\r",
      "       [ 9597],\r",
      "       [ 8153],\r",
      "       [   44],\r",
      "       [ 5456],\r",
      "       [ 8850],\r",
      "       [14546],\r",
      "       [ 4446],\r",
      "       [ 2619],\r",
      "       [13779],\r",
      "       [ 3607],\r",
      "       [  748],\r",
      "       [ 6474],\r",
      "       [14581],\r",
      "       [17570],\r",
      "       [12640],\r",
      "       [ 3407],\r",
      "       [16879],\r",
      "       [12016],\r",
      "       [12255],\r",
      "       [ 5826],\r",
      "       [ 7730],\r",
      "       [ 3378],\r",
      "       [13107],\r",
      "       [ 5980],\r",
      "       [10541],\r",
      "       [10557],\r",
      "       [12320],\r",
      "       [ 5023],\r",
      "       [ 6200],\r",
      "       [16327],\r",
      "       [15854],\r",
      "       [ 4452],\r",
      "       [ 7103],\r",
      "       [16516],\r",
      "       [10834],\r",
      "       [ 4863],\r",
      "       [  728],\r",
      "       [13444],\r",
      "       [  364],\r",
      "       [ 2500],\r",
      "       [ 4827],\r",
      "       [ 4089],\r",
      "       [13902],\r",
      "       [ 9386],\r",
      "       [16821],\r",
      "       [ 2682],\r",
      "       [13450],\r",
      "       [ 1345],\r",
      "       [ 6589],\r",
      "       [17303],\r",
      "       [ 9978],\r",
      "       [  799],\r",
      "       [10168],\r",
      "       [ 9577],\r",
      "       [11765],\r",
      "       [ 7156],\r",
      "       [ 2639],\r",
      "       [  243],\r",
      "       [14054],\r",
      "       [ 1319],\r",
      "       [ 4619],\r",
      "       [12843],\r",
      "       [ 5421],\r",
      "       [12387],\r",
      "       [16539],\r",
      "       [ 6332],\r",
      "       [ 3659],\r",
      "       [17520],\r",
      "       [10512],\r",
      "       [ 9718],\r",
      "       [ 7903],\r",
      "       [ 4338],\r",
      "       [ 2623],\r",
      "       [ 3348],\r",
      "       [17333],\r",
      "       [11527],\r",
      "       [  387],\r",
      "       [ 4174],\r",
      "       [ 4031],\r",
      "       [14963],\r",
      "       [ 9173],\r",
      "       [  732],\r",
      "       [ 3498],\r",
      "       [16556],\r",
      "       [ 7617],\r",
      "       [ 2278],\r",
      "       [14670],\r",
      "       [  289],\r",
      "       [ 5552],\r",
      "       [14461]]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\r",
      "       1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32))\r",
      "(array([[  678],\r",
      "       [ 1632],\r",
      "       [ 1636],\r",
      "       [ 5400],\r",
      "       [  227],\r",
      "       [  750],\r",
      "       [ 2667],\r",
      "       [ 2146],\r",
      "       [ 4947],\r",
      "       [ 5524],\r",
      "       [  616],\r",
      "       [ 5595],\r",
      "       [ 3569],\r",
      "       [ 9126],\r",
      "       [  110],\r",
      "       [ 3613],\r",
      "       [ 2786],\r",
      "       [ 1727],\r",
      "       [  288],\r",
      "       [  341],\r",
      "       [ 4379],\r",
      "       [11291],\r",
      "       [   20],\r",
      "       [ 5219],\r",
      "       [  298],\r",
      "       [  685],\r",
      "       [ 1114],\r",
      "       [   19],\r",
      "       [ 3749],\r",
      "       [ 2121],\r",
      "       [ 2416],\r",
      "       [ 1399],\r",
      "       [  453],\r",
      "       [ 1042],\r",
      "       [  487],\r",
      "       [   22],\r",
      "       [ 6115],\r",
      "       [ 1305],\r",
      "       [  328],\r",
      "       [   88],\r",
      "       [  684],\r",
      "       [ 1256],\r",
      "       [   79],\r",
      "       [15789],\r",
      "       [   95],\r",
      "       [15996],\r",
      "       [ 2041],\r",
      "       [  516],\r",
      "       [ 2664],\r",
      "       [ 1383],\r",
      "       [  294],\r",
      "       [ 4474],\r",
      "       [10441],\r",
      "       [  515],\r",
      "       [ 1693],\r",
      "       [ 4849],\r",
      "       [ 9555],\r",
      "       [  148],\r",
      "       [   33],\r",
      "       [11870],\r",
      "       [  805],\r",
      "       [ 4283],\r",
      "       [  986],\r",
      "       [ 1126],\r",
      "       [  896],\r",
      "       [ 1122],\r",
      "       [ 1501],\r",
      "       [ 4164],\r",
      "       [  537],\r",
      "       [14139],\r",
      "       [ 5352],\r",
      "       [  126],\r",
      "       [  193],\r",
      "       [ 2901],\r",
      "       [ 2031],\r",
      "       [  373],\r",
      "       [  223],\r",
      "       [ 2876],\r",
      "       [  479],\r",
      "       [  103],\r",
      "       [ 3380],\r",
      "       [ 1463],\r",
      "       [ 3989],\r",
      "       [ 2685],\r",
      "       [ 1275],\r",
      "       [ 9055],\r",
      "       [ 1527],\r",
      "       [  264],\r",
      "       [ 1291],\r",
      "       [ 2283],\r",
      "       [  199],\r",
      "       [  956],\r",
      "       [  575],\r",
      "       [ 4788],\r",
      "       [ 1359],\r",
      "       [  488],\r",
      "       [  885],\r",
      "       [ 1900],\r",
      "       [ 1923],\r",
      "       [  892],\r",
      "       [ 5150],\r",
      "       [15887],\r",
      "       [ 1786],\r",
      "       [  325],\r",
      "       [ 2941],\r",
      "       [  110],\r",
      "       [ 1892],\r",
      "       [  600],\r",
      "       [ 1726],\r",
      "       [  111],\r",
      "       [  676],\r",
      "       [ 7823],\r",
      "       [  639],\r",
      "       [ 6849],\r",
      "       [ 2556],\r",
      "       [   87],\r",
      "       [ 5790],\r",
      "       [  444],\r",
      "       [   19],\r",
      "       [  287],\r",
      "       [ 2407],\r",
      "       [  178],\r",
      "       [  664],\r",
      "       [ 6037],\r",
      "       [   91],\r",
      "       [ 1156],\r",
      "       [  601],\r",
      "       [ 4399]]), array([[12116],\r",
      "       [13522],\r",
      "       [ 6606],\r",
      "       [ 7558],\r",
      "       [ 7090],\r",
      "       [13531],\r",
      "       [ 5273],\r",
      "       [15949],\r",
      "       [17137],\r",
      "       [ 9049],\r",
      "       [  625],\r",
      "       [14696],\r",
      "       [   81],\r",
      "       [14894],\r",
      "       [ 8187],\r",
      "       [16652],\r",
      "       [  405],\r",
      "       [ 4919],\r",
      "       [ 9749],\r",
      "       [ 3146],\r",
      "       [15024],\r",
      "       [ 6397],\r",
      "       [ 3896],\r",
      "       [   83],\r",
      "       [ 1816],\r",
      "       [ 4481],\r",
      "       [ 3052],\r",
      "       [  432],\r",
      "       [12716],\r",
      "       [16345],\r",
      "       [15836],\r",
      "       [10440],\r",
      "       [ 2284],\r",
      "       [ 1127],\r",
      "       [17676],\r",
      "       [ 2299],\r",
      "       [ 4416],\r",
      "       [10254],\r",
      "       [17407],\r",
      "       [ 8770],\r",
      "       [ 8740],\r",
      "       [ 2894],\r",
      "       [10668],\r",
      "       [11474],\r",
      "       [17007],\r",
      "       [ 1785],\r",
      "       [ 5183],\r",
      "       [ 6760],\r",
      "       [ 1617],\r",
      "       [10250],\r",
      "       [10357],\r",
      "       [16648],\r",
      "       [ 2244],\r",
      "       [12912],\r",
      "       [15782],\r",
      "       [ 6694],\r",
      "       [  897],\r",
      "       [16526],\r",
      "       [  361],\r",
      "       [  897],\r",
      "       [13630],\r",
      "       [ 5542],\r",
      "       [13410],\r",
      "       [14946],\r",
      "       [ 4244],\r",
      "       [  715],\r",
      "       [ 7257],\r",
      "       [ 8403],\r",
      "       [ 7501],\r",
      "       [  407],\r",
      "       [ 3980],\r",
      "       [ 3614],\r",
      "       [ 1156],\r",
      "       [12211],\r",
      "       [ 6710],\r",
      "       [  242],\r",
      "       [ 9894],\r",
      "       [16972],\r",
      "       [13660],\r",
      "       [17474],\r",
      "       [ 1976],\r",
      "       [11689],\r",
      "       [ 6608],\r",
      "       [14262],\r",
      "       [12005],\r",
      "       [ 4569],\r",
      "       [15287],\r",
      "       [ 9130],\r",
      "       [16690],\r",
      "       [ 6112],\r",
      "       [ 9963],\r",
      "       [ 4203],\r",
      "       [ 4662],\r",
      "       [ 6897],\r",
      "       [ 9139],\r",
      "       [ 8957],\r",
      "       [ 7270],\r",
      "       [ 8821],\r",
      "       [   88],\r",
      "       [ 1786],\r",
      "       [13992],\r",
      "       [16049],\r",
      "       [ 9666],\r",
      "       [ 9245],\r",
      "       [ 2662],\r",
      "       [11496],\r",
      "       [ 8754],\r",
      "       [ 5324],\r",
      "       [11172],\r",
      "       [12243],\r",
      "       [16559],\r",
      "       [ 8159],\r",
      "       [ 7120],\r",
      "       [12060],\r",
      "       [ 8167],\r",
      "       [16576],\r",
      "       [10894],\r",
      "       [  666],\r",
      "       [ 6964],\r",
      "       [11090],\r",
      "       [12649],\r",
      "       [14215],\r",
      "       [  689],\r",
      "       [17323],\r",
      "       [ 7599],\r",
      "       [ 1385],\r",
      "       [10027],\r",
      "       [10753]]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\r",
      "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\r",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))\r"
     ]
    }
   ],
   "source": [
    "#构造mini-batch，准备对模型进行训练\r\n",
    "#将不同类型的数据放到不同的tensor里，便于神经网络进行处理\r\n",
    "#并通过numpy的array函数，构造出不同的tensor来，并把这些tensor送入神经网络中进行训练\r\n",
    "def build_batch(dataset, batch_size, epoch_num):\r\n",
    "    \r\n",
    "    #center_word_batch缓存batch_size个中心词\r\n",
    "    center_word_batch = []\r\n",
    "    #target_word_batch缓存batch_size个目标词（可以是正样本或者负样本）\r\n",
    "    target_word_batch = []\r\n",
    "    #label_batch缓存了batch_size个0或1的标签，用于模型训练\r\n",
    "    label_batch = []\r\n",
    "\r\n",
    "    for epoch in range(epoch_num):\r\n",
    "        #每次开启一个新epoch之前，都对数据进行一次随机打乱，提高训练效果\r\n",
    "        random.shuffle(dataset)\r\n",
    "        \r\n",
    "        for center_word, target_word, label in dataset:\r\n",
    "            #遍历dataset中的每个样本，并将这些数据送到不同的tensor里\r\n",
    "            center_word_batch.append([center_word])\r\n",
    "            target_word_batch.append([target_word])\r\n",
    "            label_batch.append(label)\r\n",
    "\r\n",
    "            #当样本积攒到一个batch_size后，把数据都返回回来\r\n",
    "            #在这里使用numpy的array函数把list封装成tensor\r\n",
    "            #并使用python的迭代器机制，将数据yield出来\r\n",
    "            #使用迭代器的好处是可以节省内存\r\n",
    "            if len(center_word_batch) == batch_size:\r\n",
    "                yield np.array(center_word_batch).astype(\"int64\"), \\\r\n",
    "                    np.array(target_word_batch).astype(\"int64\"), \\\r\n",
    "                    np.array(label_batch).astype(\"float32\")\r\n",
    "                center_word_batch = []\r\n",
    "                target_word_batch = []\r\n",
    "                label_batch = []\r\n",
    "\r\n",
    "    if len(center_word_batch) > 0:\r\n",
    "        yield np.array(center_word_batch).astype(\"int64\"), \\\r\n",
    "            np.array(target_word_batch).astype(\"int64\"), \\\r\n",
    "            np.array(label_batch).astype(\"float32\")\r\n",
    "\r\n",
    "for _, batch in zip(range(10), build_batch(dataset, 128, 3)):\r\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义skip-gram训练网络结构\r\n",
    "#这里使用的是paddlepaddle的1.7.0版本\r\n",
    "#一般来说，在使用fluid训练的时候，需要通过一个类来定义网络结构，这个类继承了fluid.dygraph.Layer\r\n",
    "class SkipGram(fluid.dygraph.Layer):\r\n",
    "    def __init__(self, vocab_size, embedding_size, init_scale=0.1):\r\n",
    "        #vocab_size定义了这个skipgram这个模型的词表大小\r\n",
    "        #embedding_size定义了词向量的维度是多少\r\n",
    "        #init_scale定义了词向量初始化的范围，一般来说，比较小的初始化范围有助于模型训练\r\n",
    "        super(SkipGram, self).__init__()\r\n",
    "        self.vocab_size = vocab_size\r\n",
    "        self.embedding_size = embedding_size\r\n",
    "\r\n",
    "        #使用paddle.fluid.dygraph提供的Embedding函数，构造一个词向量参数\r\n",
    "        #这个参数的大小为：[self.vocab_size, self.embedding_size]\r\n",
    "        #数据类型为：float32\r\n",
    "        #这个参数的名称为：embedding_para\r\n",
    "        #这个参数的初始化方式为在[-init_scale, init_scale]区间进行均匀采样\r\n",
    "        self.embedding = Embedding(\r\n",
    "            size=[self.vocab_size, self.embedding_size],\r\n",
    "            dtype='float32',\r\n",
    "            param_attr=fluid.ParamAttr(\r\n",
    "                name='embedding_para',\r\n",
    "                initializer=fluid.initializer.UniformInitializer(\r\n",
    "                    low=-0.5/embedding_size, high=0.5/embedding_size)))\r\n",
    "\r\n",
    "        #使用paddle.fluid.dygraph提供的Embedding函数，构造另外一个词向量参数\r\n",
    "        #这个参数的大小为：[self.vocab_size, self.embedding_size]\r\n",
    "        #数据类型为：float32\r\n",
    "        #这个参数的名称为：embedding_para_out\r\n",
    "        #这个参数的初始化方式为在[-init_scale, init_scale]区间进行均匀采样\r\n",
    "        #跟上面不同的是，这个参数的名称跟上面不同，因此，\r\n",
    "        #embedding_para_out和embedding_para虽然有相同的shape，但是权重不共享\r\n",
    "        self.embedding_out = Embedding(\r\n",
    "            size=[self.vocab_size, self.embedding_size],\r\n",
    "            dtype='float32',\r\n",
    "            param_attr=fluid.ParamAttr(\r\n",
    "                name='embedding_out_para',\r\n",
    "                initializer=fluid.initializer.UniformInitializer(\r\n",
    "                    low=-0.5/embedding_size, high=0.5/embedding_size)))\r\n",
    "\r\n",
    "    #定义网络的前向计算逻辑\r\n",
    "    #center_words是一个tensor（mini-batch），表示中心词\r\n",
    "    #target_words是一个tensor（mini-batch），表示目标词\r\n",
    "    #label是一个tensor（mini-batch），表示这个词是正样本还是负样本（用0或1表示）\r\n",
    "    #用于在训练中计算这个tensor中对应词的同义词，用于观察模型的训练效果\r\n",
    "    def forward(self, center_words, target_words, label):\r\n",
    "        #首先，通过embedding_para（self.embedding）参数，将mini-batch中的词转换为词向量\r\n",
    "        #这里center_words和eval_words_emb查询的是一个相同的参数\r\n",
    "        #而target_words_emb查询的是另一个参数\r\n",
    "        center_words_emb = self.embedding(center_words)\r\n",
    "        target_words_emb = self.embedding_out(target_words)\r\n",
    "\r\n",
    "        #center_words_emb = [batch_size, embedding_size]\r\n",
    "        #target_words_emb = [batch_size, embedding_size]\r\n",
    "        #通过点乘的方式计算中心词到目标词的输出概率，并通过sigmoid函数估计这个词是正样本还是负样本的概率。\r\n",
    "        word_sim = fluid.layers.elementwise_mul(center_words_emb, target_words_emb)\r\n",
    "        word_sim = fluid.layers.reduce_sum(word_sim, dim = -1)\r\n",
    "        word_sim = fluid.layers.reshape(word_sim, shape=[-1])\r\n",
    "        pred = fluid.layers.sigmoid(word_sim)\r\n",
    "\r\n",
    "        #通过估计的输出概率定义损失函数，注意使用的是sigmoid_cross_entropy_with_logits函数\r\n",
    "        #将sigmoid计算和cross entropy合并成一步计算可以更好的优化，所以输入的是word_sim，而不是pred\r\n",
    "        \r\n",
    "        loss = fluid.layers.sigmoid_cross_entropy_with_logits(word_sim, label)\r\n",
    "        loss = fluid.layers.reduce_mean(loss)\r\n",
    "\r\n",
    "        #返回前向计算的结果，飞桨会通过backward函数自动计算出反向结果。\r\n",
    "        return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100, loss 0.693\n",
      "step 200, loss 0.692\n",
      "step 300, loss 0.687\n",
      "step 400, loss 0.655\n",
      "step 500, loss 0.584\n",
      "step 600, loss 0.473\n",
      "step 700, loss 0.441\n",
      "step 800, loss 0.347\n",
      "step 900, loss 0.329\n",
      "step 1000, loss 0.286\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 舞蹈\n",
      "for word 病毒, the similar word is 流水\n",
      "for word 病毒, the similar word is 信\n",
      "for word 病毒, the similar word is 醉人\n",
      "for word 病毒, the similar word is 长寿\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 小女孩\n",
      "for word 病毒, the similar word is 大气\n",
      "for word 病毒, the similar word is 感人\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 小心\n",
      "for word 钟南山, the similar word is 母亲\n",
      "for word 钟南山, the similar word is 妻子\n",
      "for word 钟南山, the similar word is 大家\n",
      "for word 钟南山, the similar word is 老公\n",
      "for word 钟南山, the similar word is 文\n",
      "for word 钟南山, the similar word is 情歌\n",
      "for word 钟南山, the similar word is 祝你开心\n",
      "for word 钟南山, the similar word is 图\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 母亲\n",
      "for word 武汉, the similar word is 美女\n",
      "for word 武汉, the similar word is 同学\n",
      "for word 武汉, the similar word is 老公\n",
      "for word 武汉, the similar word is 深情\n",
      "for word 武汉, the similar word is 人生\n",
      "for word 武汉, the similar word is 经典\n",
      "for word 武汉, the similar word is 歌\n",
      "for word 武汉, the similar word is 全世界\n",
      "step 1100, loss 0.303\n",
      "step 1200, loss 0.269\n",
      "step 1300, loss 0.297\n",
      "step 1400, loss 0.278\n",
      "step 1500, loss 0.278\n",
      "step 1600, loss 0.288\n",
      "step 1700, loss 0.265\n",
      "step 1800, loss 0.218\n",
      "step 1900, loss 0.265\n",
      "step 2000, loss 0.246\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 段子\n",
      "for word 病毒, the similar word is 原因\n",
      "for word 病毒, the similar word is 老板\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 血栓\n",
      "for word 病毒, the similar word is 大气\n",
      "for word 病毒, the similar word is 糖尿病\n",
      "for word 病毒, the similar word is 高血压\n",
      "for word 病毒, the similar word is 妻子\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 妻子\n",
      "for word 钟南山, the similar word is 小心\n",
      "for word 钟南山, the similar word is 好消息\n",
      "for word 钟南山, the similar word is 母亲\n",
      "for word 钟南山, the similar word is 祝你开心\n",
      "for word 钟南山, the similar word is 太牛\n",
      "for word 钟南山, the similar word is 大家\n",
      "for word 钟南山, the similar word is 气势\n",
      "for word 钟南山, the similar word is 流泪\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 母亲\n",
      "for word 武汉, the similar word is 女兵\n",
      "for word 武汉, the similar word is 年度\n",
      "for word 武汉, the similar word is 深情\n",
      "for word 武汉, the similar word is 韩红\n",
      "for word 武汉, the similar word is 太牛\n",
      "for word 武汉, the similar word is 总结\n",
      "for word 武汉, the similar word is 老祖宗\n",
      "for word 武汉, the similar word is 同学\n",
      "step 2100, loss 0.226\n",
      "step 2200, loss 0.223\n",
      "step 2300, loss 0.237\n",
      "step 2400, loss 0.241\n",
      "step 2500, loss 0.246\n",
      "step 2600, loss 0.289\n",
      "step 2700, loss 0.232\n",
      "step 2800, loss 0.269\n",
      "step 2900, loss 0.295\n",
      "step 3000, loss 0.251\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 同学\n",
      "for word 病毒, the similar word is 大牙\n",
      "for word 病毒, the similar word is 意思\n",
      "for word 病毒, the similar word is 工程\n",
      "for word 病毒, the similar word is 杯酒\n",
      "for word 病毒, the similar word is 短信\n",
      "for word 病毒, the similar word is 老板\n",
      "for word 病毒, the similar word is 学会\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 武汉\n",
      "for word 钟南山, the similar word is 肺炎\n",
      "for word 钟南山, the similar word is 李兰娟\n",
      "for word 钟南山, the similar word is 部队\n",
      "for word 钟南山, the similar word is 气势\n",
      "for word 钟南山, the similar word is 好消息\n",
      "for word 钟南山, the similar word is 妻子\n",
      "for word 钟南山, the similar word is 牙\n",
      "for word 钟南山, the similar word is 朋友圈\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 同学\n",
      "for word 武汉, the similar word is 祝你开心\n",
      "for word 武汉, the similar word is 新冠\n",
      "for word 武汉, the similar word is 祝你幸福\n",
      "for word 武汉, the similar word is 妈妈\n",
      "for word 武汉, the similar word is 时期\n",
      "for word 武汉, the similar word is 肺炎\n",
      "for word 武汉, the similar word is 太牛\n",
      "for word 武汉, the similar word is 美女\n",
      "step 3100, loss 0.226\n",
      "step 3200, loss 0.247\n",
      "step 3300, loss 0.285\n",
      "step 3400, loss 0.282\n",
      "step 3500, loss 0.283\n",
      "step 3600, loss 0.268\n",
      "step 3700, loss 0.254\n",
      "step 3800, loss 0.200\n",
      "step 3900, loss 0.299\n",
      "step 4000, loss 0.186\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 工程\n",
      "for word 病毒, the similar word is 同学\n",
      "for word 病毒, the similar word is 学会\n",
      "for word 病毒, the similar word is 雨\n",
      "for word 病毒, the similar word is 杯酒\n",
      "for word 病毒, the similar word is 孝顺父母\n",
      "for word 病毒, the similar word is 笑点\n",
      "for word 病毒, the similar word is 地球\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 李兰娟\n",
      "for word 钟南山, the similar word is 好消息\n",
      "for word 钟南山, the similar word is 消息\n",
      "for word 钟南山, the similar word is 气势\n",
      "for word 钟南山, the similar word is 流泪\n",
      "for word 钟南山, the similar word is 新冠\n",
      "for word 钟南山, the similar word is 家\n",
      "for word 钟南山, the similar word is 封城\n",
      "for word 钟南山, the similar word is 心语\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 深情\n",
      "for word 武汉, the similar word is 祝你幸福\n",
      "for word 武汉, the similar word is 中国\n",
      "for word 武汉, the similar word is 军人\n",
      "for word 武汉, the similar word is 新冠\n",
      "for word 武汉, the similar word is 消息\n",
      "for word 武汉, the similar word is 军歌\n",
      "for word 武汉, the similar word is 朋友\n",
      "for word 武汉, the similar word is 钟南山\n",
      "step 4100, loss 0.225\n",
      "step 4200, loss 0.224\n",
      "step 4300, loss 0.238\n",
      "step 4400, loss 0.230\n",
      "step 4500, loss 0.185\n",
      "step 4600, loss 0.282\n",
      "step 4700, loss 0.256\n",
      "step 4800, loss 0.228\n",
      "step 4900, loss 0.215\n",
      "step 5000, loss 0.232\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 同学\n",
      "for word 病毒, the similar word is 工程\n",
      "for word 病毒, the similar word is 疫苗\n",
      "for word 病毒, the similar word is 笑点\n",
      "for word 病毒, the similar word is 喜讯\n",
      "for word 病毒, the similar word is 舞台\n",
      "for word 病毒, the similar word is 人才\n",
      "for word 病毒, the similar word is 杯酒\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 李兰娟\n",
      "for word 钟南山, the similar word is 新冠\n",
      "for word 钟南山, the similar word is 警告\n",
      "for word 钟南山, the similar word is 集市\n",
      "for word 钟南山, the similar word is 金子般\n",
      "for word 钟南山, the similar word is 封城\n",
      "for word 钟南山, the similar word is 好消息\n",
      "for word 钟南山, the similar word is 喜讯\n",
      "for word 钟南山, the similar word is 保卫战\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 新冠\n",
      "for word 武汉, the similar word is 祝你幸福\n",
      "for word 武汉, the similar word is 时期\n",
      "for word 武汉, the similar word is 消息\n",
      "for word 武汉, the similar word is 喜讯\n",
      "for word 武汉, the similar word is 祝你开心\n",
      "for word 武汉, the similar word is 钟南山\n",
      "for word 武汉, the similar word is 司机\n",
      "for word 武汉, the similar word is 封城\n",
      "step 5100, loss 0.213\n",
      "step 5200, loss 0.221\n",
      "step 5300, loss 0.219\n",
      "step 5400, loss 0.194\n",
      "step 5500, loss 0.199\n",
      "step 5600, loss 0.313\n",
      "step 5700, loss 0.258\n",
      "step 5800, loss 0.243\n",
      "step 5900, loss 0.225\n",
      "step 6000, loss 0.248\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 工程\n",
      "for word 病毒, the similar word is 静脉\n",
      "for word 病毒, the similar word is 疫苗\n",
      "for word 病毒, the similar word is 粪便\n",
      "for word 病毒, the similar word is 出院\n",
      "for word 病毒, the similar word is 鬼才\n",
      "for word 病毒, the similar word is 流感\n",
      "for word 病毒, the similar word is 地球\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 李兰娟\n",
      "for word 钟南山, the similar word is 疫情\n",
      "for word 钟南山, the similar word is 武汉\n",
      "for word 钟南山, the similar word is 新冠\n",
      "for word 钟南山, the similar word is 好消息\n",
      "for word 钟南山, the similar word is 消息\n",
      "for word 钟南山, the similar word is 肺炎\n",
      "for word 钟南山, the similar word is 警告\n",
      "for word 钟南山, the similar word is 部队\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 新冠\n",
      "for word 武汉, the similar word is 好消息\n",
      "for word 武汉, the similar word is 司机\n",
      "for word 武汉, the similar word is 时期\n",
      "for word 武汉, the similar word is 大事\n",
      "for word 武汉, the similar word is 消息\n",
      "for word 武汉, the similar word is 衣\n",
      "for word 武汉, the similar word is 顺顺利利\n",
      "for word 武汉, the similar word is 抗日\n",
      "step 6100, loss 0.191\n",
      "step 6200, loss 0.285\n",
      "step 6300, loss 0.218\n",
      "step 6400, loss 0.216\n",
      "step 6500, loss 0.237\n",
      "step 6600, loss 0.304\n",
      "step 6700, loss 0.264\n",
      "step 6800, loss 0.256\n",
      "step 6900, loss 0.249\n",
      "step 7000, loss 0.216\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 工程\n",
      "for word 病毒, the similar word is 疫苗\n",
      "for word 病毒, the similar word is 出院\n",
      "for word 病毒, the similar word is 流感\n",
      "for word 病毒, the similar word is 粪便\n",
      "for word 病毒, the similar word is 鬼才\n",
      "for word 病毒, the similar word is 地球\n",
      "for word 病毒, the similar word is 喜讯\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 李兰娟\n",
      "for word 钟南山, the similar word is 肺炎\n",
      "for word 钟南山, the similar word is 疫情\n",
      "for word 钟南山, the similar word is 好消息\n",
      "for word 钟南山, the similar word is 消息\n",
      "for word 钟南山, the similar word is 新冠\n",
      "for word 钟南山, the similar word is 武汉\n",
      "for word 钟南山, the similar word is 警告\n",
      "for word 钟南山, the similar word is 阿比\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 新冠\n",
      "for word 武汉, the similar word is 钟南山\n",
      "for word 武汉, the similar word is 时期\n",
      "for word 武汉, the similar word is 消息\n",
      "for word 武汉, the similar word is 解放军\n",
      "for word 武汉, the similar word is 好消息\n",
      "for word 武汉, the similar word is 李兰娟\n",
      "for word 武汉, the similar word is 大事\n",
      "for word 武汉, the similar word is 抗日\n",
      "step 7100, loss 0.230\n",
      "step 7200, loss 0.232\n",
      "step 7300, loss 0.255\n",
      "step 7400, loss 0.359\n",
      "step 7500, loss 0.210\n",
      "step 7600, loss 0.202\n",
      "step 7700, loss 0.225\n",
      "step 7800, loss 0.218\n",
      "step 7900, loss 0.201\n",
      "step 8000, loss 0.247\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 疫苗\n",
      "for word 病毒, the similar word is 工程\n",
      "for word 病毒, the similar word is 患者\n",
      "for word 病毒, the similar word is 出院\n",
      "for word 病毒, the similar word is 地球\n",
      "for word 病毒, the similar word is 新冠\n",
      "for word 病毒, the similar word is 鬼才\n",
      "for word 病毒, the similar word is 舞台\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 李兰娟\n",
      "for word 钟南山, the similar word is 武汉\n",
      "for word 钟南山, the similar word is 肺炎\n",
      "for word 钟南山, the similar word is 疫情\n",
      "for word 钟南山, the similar word is 新冠\n",
      "for word 钟南山, the similar word is 警告\n",
      "for word 钟南山, the similar word is 消息\n",
      "for word 钟南山, the similar word is 阿比\n",
      "for word 钟南山, the similar word is 拐点\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 新冠\n",
      "for word 武汉, the similar word is 钟南山\n",
      "for word 武汉, the similar word is 封城\n",
      "for word 武汉, the similar word is 院士\n",
      "for word 武汉, the similar word is 拐点\n",
      "for word 武汉, the similar word is 小精灵\n",
      "for word 武汉, the similar word is 李兰娟\n",
      "for word 武汉, the similar word is 时期\n",
      "for word 武汉, the similar word is 计划\n",
      "step 8100, loss 0.175\n",
      "step 8200, loss 0.199\n",
      "step 8300, loss 0.198\n",
      "step 8400, loss 0.156\n",
      "step 8500, loss 0.250\n",
      "step 8600, loss 0.200\n",
      "step 8700, loss 0.200\n",
      "step 8800, loss 0.215\n",
      "step 8900, loss 0.211\n",
      "step 9000, loss 0.225\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 疫苗\n",
      "for word 病毒, the similar word is 工程\n",
      "for word 病毒, the similar word is 出院\n",
      "for word 病毒, the similar word is 流感\n",
      "for word 病毒, the similar word is 鬼才\n",
      "for word 病毒, the similar word is 新冠\n",
      "for word 病毒, the similar word is 静脉\n",
      "for word 病毒, the similar word is 性本善\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 李兰娟\n",
      "for word 钟南山, the similar word is 肺炎\n",
      "for word 钟南山, the similar word is 新冠\n",
      "for word 钟南山, the similar word is 消息\n",
      "for word 钟南山, the similar word is 疫情\n",
      "for word 钟南山, the similar word is 武汉\n",
      "for word 钟南山, the similar word is 患者\n",
      "for word 钟南山, the similar word is 拐点\n",
      "for word 钟南山, the similar word is 好消息\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 新冠\n",
      "for word 武汉, the similar word is 钟南山\n",
      "for word 武汉, the similar word is 时期\n",
      "for word 武汉, the similar word is 院士\n",
      "for word 武汉, the similar word is 消息\n",
      "for word 武汉, the similar word is 疫苗\n",
      "for word 武汉, the similar word is 李兰娟\n",
      "for word 武汉, the similar word is 封城\n",
      "for word 武汉, the similar word is 疫情\n",
      "step 9100, loss 0.212\n",
      "step 9200, loss 0.202\n",
      "step 9300, loss 0.156\n",
      "step 9400, loss 0.251\n",
      "step 9500, loss 0.227\n",
      "step 9600, loss 0.198\n",
      "step 9700, loss 0.187\n",
      "step 9800, loss 0.217\n",
      "step 9900, loss 0.178\n",
      "step 10000, loss 0.188\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 疫苗\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 工程\n",
      "for word 病毒, the similar word is 流感\n",
      "for word 病毒, the similar word is 出院\n",
      "for word 病毒, the similar word is 性本善\n",
      "for word 病毒, the similar word is 东方红一号\n",
      "for word 病毒, the similar word is 阳性\n",
      "for word 病毒, the similar word is 鬼才\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 李兰娟\n",
      "for word 钟南山, the similar word is 武汉\n",
      "for word 钟南山, the similar word is 肺炎\n",
      "for word 钟南山, the similar word is 新冠\n",
      "for word 钟南山, the similar word is 消息\n",
      "for word 钟南山, the similar word is 流感\n",
      "for word 钟南山, the similar word is 警告\n",
      "for word 钟南山, the similar word is 保卫战\n",
      "for word 钟南山, the similar word is 疫情\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 新冠\n",
      "for word 武汉, the similar word is 钟南山\n",
      "for word 武汉, the similar word is 流感\n",
      "for word 武汉, the similar word is 疫苗\n",
      "for word 武汉, the similar word is 李兰娟\n",
      "for word 武汉, the similar word is 阳性\n",
      "for word 武汉, the similar word is 入境\n",
      "for word 武汉, the similar word is 关天\n",
      "for word 武汉, the similar word is 南山\n",
      "step 10100, loss 0.214\n",
      "step 10200, loss 0.287\n",
      "step 10300, loss 0.240\n",
      "step 10400, loss 0.173\n",
      "step 10500, loss 0.246\n",
      "step 10600, loss 0.208\n",
      "step 10700, loss 0.176\n",
      "step 10800, loss 0.207\n",
      "step 10900, loss 0.208\n",
      "step 11000, loss 0.195\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 疫苗\n",
      "for word 病毒, the similar word is 工程\n",
      "for word 病毒, the similar word is 流感\n",
      "for word 病毒, the similar word is 出院\n",
      "for word 病毒, the similar word is 阳性\n",
      "for word 病毒, the similar word is 性本善\n",
      "for word 病毒, the similar word is 重大成果\n",
      "for word 病毒, the similar word is 新冠\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 李兰娟\n",
      "for word 钟南山, the similar word is 新冠\n",
      "for word 钟南山, the similar word is 肺炎\n",
      "for word 钟南山, the similar word is 武汉\n",
      "for word 钟南山, the similar word is 疫情\n",
      "for word 钟南山, the similar word is 消息\n",
      "for word 钟南山, the similar word is 阿比\n",
      "for word 钟南山, the similar word is 流感\n",
      "for word 钟南山, the similar word is 病人\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 新冠\n",
      "for word 武汉, the similar word is 钟南山\n",
      "for word 武汉, the similar word is 阳性\n",
      "for word 武汉, the similar word is 院士\n",
      "for word 武汉, the similar word is 李兰娟\n",
      "for word 武汉, the similar word is 流感\n",
      "for word 武汉, the similar word is 南山\n",
      "for word 武汉, the similar word is 时期\n",
      "for word 武汉, the similar word is 病人\n",
      "step 11100, loss 0.223\n",
      "step 11200, loss 0.180\n",
      "step 11300, loss 0.250\n",
      "step 11400, loss 0.175\n",
      "step 11500, loss 0.229\n",
      "step 11600, loss 0.215\n",
      "step 11700, loss 0.171\n",
      "step 11800, loss 0.224\n",
      "step 11900, loss 0.185\n",
      "step 12000, loss 0.289\n",
      "for word 病毒, the similar word is 病毒\n",
      "for word 病毒, the similar word is 肺炎\n",
      "for word 病毒, the similar word is 疫苗\n",
      "for word 病毒, the similar word is 出院\n",
      "for word 病毒, the similar word is 流感\n",
      "for word 病毒, the similar word is 静脉\n",
      "for word 病毒, the similar word is 重大成果\n",
      "for word 病毒, the similar word is 东方红一号\n",
      "for word 病毒, the similar word is 全纪录\n",
      "for word 病毒, the similar word is 工程\n",
      "for word 钟南山, the similar word is 钟南山\n",
      "for word 钟南山, the similar word is 李兰娟\n",
      "for word 钟南山, the similar word is 肺炎\n",
      "for word 钟南山, the similar word is 新冠\n",
      "for word 钟南山, the similar word is 疫情\n",
      "for word 钟南山, the similar word is 武汉\n",
      "for word 钟南山, the similar word is 阿比\n",
      "for word 钟南山, the similar word is 流感\n",
      "for word 钟南山, the similar word is 警告\n",
      "for word 钟南山, the similar word is 拐点\n",
      "for word 武汉, the similar word is 武汉\n",
      "for word 武汉, the similar word is 新冠\n",
      "for word 武汉, the similar word is 阳性\n",
      "for word 武汉, the similar word is 钟南山\n",
      "for word 武汉, the similar word is 全纪录\n",
      "for word 武汉, the similar word is 立案\n",
      "for word 武汉, the similar word is 李兰娟\n",
      "for word 武汉, the similar word is 院士\n",
      "for word 武汉, the similar word is 流感\n",
      "for word 武汉, the similar word is 南山\n",
      "step 12100, loss 0.202\n"
     ]
    }
   ],
   "source": [
    "#开始训练，定义一些训练过程中需要使用的超参数\r\n",
    "batch_size = 512\r\n",
    "epoch_num = 3\r\n",
    "embedding_size = 200\r\n",
    "step = 0\r\n",
    "learning_rate = 0.001\r\n",
    "\r\n",
    "#定义一个使用word-embedding查询同义词的函数\r\n",
    "#这个函数query_token是要查询的词，k表示要返回多少个最相似的词，embed是学习到的word-embedding参数\r\n",
    "#通过计算不同词之间的cosine距离，来衡量词和词的相似度\r\n",
    "#具体实现如下，x代表要查询词的Embedding，Embedding参数矩阵W代表所有词的Embedding\r\n",
    "#两者计算Cos得出所有词对查询词的相似度得分向量，排序取top_k放入indices列表\r\n",
    "def get_similar_tokens(query_token, k, embed):\r\n",
    "    W = embed.numpy()\r\n",
    "    x = W[word2id_dict[query_token]]\r\n",
    "    cos = np.dot(W, x) / np.sqrt(np.sum(W * W, axis=1) * np.sum(x * x) + 1e-9)\r\n",
    "    flat = cos.flatten()\r\n",
    "    indices = np.argpartition(flat, -k)[-k:]\r\n",
    "    indices = indices[np.argsort(-flat[indices])]\r\n",
    "    for i in indices:\r\n",
    "        print('for word %s, the similar word is %s' % (query_token, str(id2word_dict[i])))\r\n",
    "\r\n",
    "#将模型放到GPU上训练（fluid.CUDAPlace(0)），如果需要指定CPU，则需要改为fluid.CPUPlace()\r\n",
    "with fluid.dygraph.guard(fluid.CPUPlace()):\r\n",
    "    #通过定义的SkipGram类，来构造一个Skip-gram模型网络\r\n",
    "    skip_gram_model = SkipGram(vocab_size, embedding_size)\r\n",
    "    #构造训练这个网络的优化器\r\n",
    "    adam = fluid.optimizer.AdamOptimizer(learning_rate=learning_rate, parameter_list = skip_gram_model.parameters())\r\n",
    "\r\n",
    "    #使用build_batch函数，以mini-batch为单位，遍历训练数据，并训练网络\r\n",
    "    for center_words, target_words, label in build_batch(\r\n",
    "        dataset, batch_size, epoch_num):\r\n",
    "        #使用fluid.dygraph.to_variable函数，将一个numpy的tensor，转换为飞桨可计算的tensor\r\n",
    "        center_words_var = fluid.dygraph.to_variable(center_words)\r\n",
    "        target_words_var = fluid.dygraph.to_variable(target_words)\r\n",
    "        label_var = fluid.dygraph.to_variable(label)\r\n",
    "\r\n",
    "        #将转换后的tensor送入飞桨中，进行一次前向计算，并得到计算结果\r\n",
    "        pred, loss = skip_gram_model(\r\n",
    "            center_words_var, target_words_var, label_var)\r\n",
    "\r\n",
    "        #通过backward函数，让程序自动完成反向计算\r\n",
    "        loss.backward()\r\n",
    "        #通过minimize函数，让程序根据loss，完成一步对参数的优化更新\r\n",
    "        adam.minimize(loss)\r\n",
    "        #使用clear_gradients函数清空模型中的梯度，以便于下一个mini-batch进行更新\r\n",
    "        skip_gram_model.clear_gradients()\r\n",
    "\r\n",
    "        #每经过100个mini-batch，打印一次当前的loss，看看loss是否在稳定下降\r\n",
    "        step += 1\r\n",
    "        if step % 100 == 0:\r\n",
    "            print(\"step %d, loss %.3f\" % (step, loss.numpy()[0]))\r\n",
    "\r\n",
    "        #经过10000个mini-batch，打印一次模型对eval_words中的10个词计算的同义词\r\n",
    "        #这里使用词和词之间的向量点积作为衡量相似度的方法\r\n",
    "        #只打印了10个最相似的词\r\n",
    "        if step % 1000 == 0:\r\n",
    "            get_similar_tokens('病毒', 10, skip_gram_model.embedding.weight)\r\n",
    "            get_similar_tokens('钟南山', 10, skip_gram_model.embedding.weight)\r\n",
    "            get_similar_tokens('武汉', 10, skip_gram_model.embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for word 肺炎, the similar word is 肺炎\n",
      "for word 肺炎, the similar word is 疫苗\n",
      "for word 肺炎, the similar word is 勤洗手\n",
      "for word 肺炎, the similar word is 朱广权\n",
      "for word 肺炎, the similar word is 阳性\n",
      "for word 肺炎, the similar word is 流感\n",
      "for word 肺炎, the similar word is 重大成果\n",
      "for word 肺炎, the similar word is 最高人民检察院\n",
      "for word 肺炎, the similar word is 病毒\n",
      "for word 肺炎, the similar word is 全纪录\n",
      "for word 肺炎, the similar word is 法医\n",
      "for word 肺炎, the similar word is 钟南山\n",
      "for word 肺炎, the similar word is 发明人\n",
      "for word 肺炎, the similar word is 费用\n",
      "for word 肺炎, the similar word is 德塞\n",
      "for word 肺炎, the similar word is 二龙\n",
      "for word 肺炎, the similar word is 粮价\n",
      "for word 肺炎, the similar word is 新冠\n",
      "for word 肺炎, the similar word is 中文\n",
      "for word 肺炎, the similar word is 李兰娟\n"
     ]
    }
   ],
   "source": [
    "get_similar_tokens('肺炎', 20, skip_gram_model.embedding.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
